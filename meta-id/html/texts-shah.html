<p class="headerlogo2"><a href="welcome.html" target="_self">META</a></p>
<p><span class="menuwelcome">TEXT</span><br>

<p><br>

 <span class="authorname">Nishant Shah</span><br>
 <span class="black200percentcapitalize">The Need for Intent and Affect</span><br>
 <span class="black200percent">An Apology for Fake News in the Digital Era</span><br>
<br><br>
  
 <span class="bold">Two proposals to start us off &hellip;</span><br>
<br>
 

We might want to believe that we live in the era of fake news, and that this is unprecedented in history. The ways in which popular media and often times scholarly discourse deals with this rise of non-traditional media production makes a case for how we were blindsided by it. In the wake of this alternative information explosion, there are some hardwired responses that we fall back on. We either ask that a distinction is made between real and fake information, trying to implement the older structures of information verification into our rapidly disruptive and disrupted information and data landscapes. Or we ask for a moral judgement to be made, suggesting that the information that emerges from central structures such as the state and media be considered sacrosanct, objective, and true, whereas all other sources be forced into producing the conditions of verification and truth-telling to which we are accustomed. In this essay, I want to propose that both of these responses need to be examined through the following two arguments. First, the way that information is, and has been, sifted and established has changed throughout history. The truthiness of information needs to be understood as contingently shaped by a series of transitions made in the digital turn. Second, it is inaccurate to think of all alternative media or <span class="italic">fake news</span> as merely malicious in intent. Rather, we need to consider their potential for radical subversion of the truth-telling monopolies that have been held by the current gatekeepers of information.<br>
<br>
 
<span class="bold">Let’s start at the very beginning &hellip;</span><br>

 <br>

In the twelfth and thirteenth centuries in Europe, before movable type was transported along trade routes and missionary trails from China to be discovered by Johannes Gutenberg who fabricated them in metal alloys, information dissemination was through scribal cultures. Scribes trained in the religious orders of the Church found themselves painstakingly copying the Holy Writ, page after page, letter by letter, making copies that would be circulated and distributed across the regions. However, as Mark Rose (1999), the historian of reading and writing points out in his work, the scribal cultures were far from prototypical photocopiers. As the scribes went about their ordained task of copying, they added meter, corrected spelling, changed the scansion, translated contexts, and in their act of circulation, continued to change, rearrange, and reformat the text so that many different versions, editions and iterations emerged over time. These scribes, even though they produced <span class="italic">new</span> texts, were authorised to make these changes that deviated from the One Word. As philosopher Michel Foucault would describe it, the sovereign and divine power that authorised the scribes conferred legitimacy to these changes. Foucault (1975) suggests that this feudal divine power of »rejection, exclusion, refusal, blockage, concealment or mask« means that anything that it brings forth automagically gains the validity of authority.<br>
<br>

 

I begin with this anecdote because it portrays, in its simplest forms, the ways in which information has gained validity. Across civilisations and centuries, this has been one of the primary ways by which we have verified what is true and what is not. This anecdote reminds us that there is nothing about information that marks it as inherently truthful or accurate. Jacques Ranciere (1991) in his philosophy on learning warns us that the only difference between information and rumour is that rumour lacks both the <span class="italic">signature</span> of the point of origin as well as a relationship with an external referent that can be verified. Similarly, Lawrence Liang (2011) in his critique of collaborative knowledge production and archiving postulates that the truthiness of information depends entirely on how it is constructed through legal, state, and collective apparatus of consensus building. The rhetorician and new media educator Elizabeth Losh (2014) furthers this point when she says that our information gains currency not only in its content but in the structures of rhetoric upon which it is mounted. New Media scholar and cultural critic Wendy Chun (2008) has shown how, especially within the digital networks, information finds validity not by an imaginary relationship with the outside, but in its fidelity with itself &mdash; a phenomenon that she succinctly describes as an <span class="italic">opaque metaphor</span>.<span class="footnoteintext"><sup>1</sup></span><br>
<br>

 

To make a short story of these various interventions, it is clear that information in itself does not have truth value. The <span class="italic">truthiness</span> of information is triangulated within the conditions of authorship, the structures of authority, and the measurements of authenticity that can render this information legible. Thus, we have a history of deciding what information is real and what is fake, what information is readable and what is illegitimate, what information is authentic and what is doctored and how it shall be received. While there is an urgency around fake news in the contemporary political landscape, we are trying to achieve illusory standards of determining what is fake and naturalising that all fake information is bad information. Especially with the American-driven global media, there has been a denouncement of <span class="italic">fake news</span> and a demand for true, real, and authentic information. The demands for this mythical information which is true in itself have now reached such cacophonic volume that there is increased pressure on Information Circulation companies like Facebook and Google to attempt algorithmic ways of weeding out false information or fake news while still upholding the rights to free speech and expression.<br>
<br>

 

These attempts to achieve <span class="italic">authentic</span> and <span class="italic">real</span> news cover over the fact that our information systems of transmission and circulation have always depended on structures of power that have legitimized desirable information. This demand for authentic news also denies the promise of digital media and web 2.0 platforms to liberate information from the tyranny of representation. Our representational frameworks insist that information has a clear and verifiable relationship with objectively measured phenomena that it seeks to describe. This mythical imagination of an objective reality which can be faithfully copied in different textual cultures is not just laughable but also ignorant of the scribal history that I began with. Because, as we can glean from the ways in which the scribes were authorised to copy, change, and deviate from the original word, there was no such thing as an objective or even a metaphysical reality. The scribes were changing things based on their affective, emotional, subjective states and faculties of interpretation that allowed for the network of religious communication to expand. There has never been an objective criterion by which things can be judged real or not, and the pronouncements of fakeness are merely the manifestations of dominant ideological structures.<br>
<br>

 

 
<span class="bold150percent">Faking it in the digital turn</span><br>
<br>

 

Hence, we come to examine the current paranoia around fake news in the digital cycles, it might be a good idea to step away from the fear mongering and pseudo ethical anxieties about real or fake information. Instead, it might be more interesting to understand the new conditions of information and data production and circulation in the digital networks. These new conditions could be marked through three transitions that we experience as we move to the digital networks: A transition from representation to simulation, from authorisation to authentication, and from veracity to verification. As I describe these conditions, I hope you will realise that this is something we already implicitly know in our digital interactions, but that making the logic and logistics of these engagements explicit would make things more concrete.<br>
<br>

 
<span class="bold">From representation to simulation </span><br>
<br>
Information has value because it refers to an external reality. Information becomes a parallel universe which finds its relevance and reference in externally measured, objectively presented phenomenon. Thus, when there is a dispute over the truthfulness or interpretation of information, the eventual measure is the objective location &mdash;  the person, the place, the location, the time &mdash; that can resolve the debate. Within this representational aesthetic, information always has an origin point and a destination that is outside of the information, and thus information is often thought of as an agnostic pack of meanings that can be transmitted without loss, as can be seen in the most basic Shannon and Weaver (1948) communication models.<br>
<br>

 

However, with the digital distribution of information, we have a system of simulation which no longer resorts to the logic of representation. As new media scholar Martin Warnke at the Media Culture of Computer Simulation (MECS) lab in Germany very precisely argues, drawing from work done in computation, physics and art, the measure of simulation is itself. If a simulation works, the verification it needs is a verification of the laws that it is built on. Take global climate change models for instance. We know that these climate change models are built on information that is incomplete because we do not have long term historical records of climate across the globe. While we do have robust data about certain phenomena from specific geographies and time periods, there is no denying that while speaking of tens of thousands of years of time-line, a lot of the data in these models is simulated &mdash; or in other words, fake data. This is data that is plausible but can have no external referent which can actually prove its truthiness. Thus, when a climate change simulation works, what it proves is that the predictive data sets and the algorithmic correlations and causalities that were established in that simulation actually work in this simulated environment. It can have potential connections with our lived climates and physical geography but there is no direct correlation between the two. In other words, the global climate change models are not a description of the real as it was, nor are they an assured prescription of the future. This is one of the reasons why climate change scientists are unwilling to make assured claims of an impending apocalypse, and this allows for climate change deniers to stake credence in their own snake oil beliefs about the future of the planet.<br>
<br>

 

What is particularly significant in this transition into simulation is that we can no longer depend on an external event to mark something as truthful or otherwise. Thus, the serving president of the United States of America instructed his communications director to present <span class="italic">alternative facts</span> about the size of crowds at his inauguration ceremony, as the first piece of public (mis)information. This is not a moral judgement on whether or not it is a lie. Instead, this is illustrative of how the current state of the digital has collapsed the sovereign-divine power that once supported the scribes in their versions of the Bible, to the extent that we now have a hunger-games style information war in which each information source competes to claim its own internal references without the demand for legitimation. This particular collapse of a central measurement system is the new condition of the digital that is shaping the world in all its virtual connections and predictions.<br>
<br>

 
<span class="bold">From veracity to verification</span><br>
<br>

 

At the core of older information regimes was a humanist ideology. We believed that human beings with their experience, their memory, and their emotional state are capable of ascribing veracity to information. Thus, if there was ever an argument about something that happened to you, at the end of the day, in the absence of documented evidence, your version of the tale would be accepted as more truthful than somebody else’s. Similarly, in our conversations around identity politics, we believe that a person who belongs to a particular identity group might have more credence in their version of events. This has often been how polarised arguments around interpretations are resolved. This works because we believe that veracity is essentially a humanist condition rather than an informational one. The bearer of ideas &mdash; as the cultural analyst Siegfried Kracauer (1995) points out &mdash; has the privilege of being also the truth teller. This informs our obsession with the first point of origin and the genealogy of truth-claims, which makes us believe that if we can source information to an originary point, we will be able to absolve it of its lapsarian sins.<br>
<br>

 

Within digital networks, though, this idea of an information trail of veracity is replaced by a data trace of verification. Whereas before, the human was the measure of truth, in digital networked systems the human has to measure up to the truth that has already been established as non-negotiable within the digital systems. Ashish Rajadhyaksha, a film and media scholar who has done one of the most critical ethnographies of the biometric database building system in India, Aaddhaar, points to this phenomenon through a very telling example. Rajadhyaksha (2013) shows how the biometric system has shifted with the introduction of digital networked databases. Older biometric systems would recognise the human as the truth and seek to find a representation of this truth of existence in different informational systems. Thus, if there was ever a discrepancy between the recorded data and the individual claimant, it would be the record that would need revision. With digital systems, while the individual can still correct information at the point of its submission to the database, once the data has been stored in dispersed self-learning systems, the possibility for the individual to change this data is diminished. Increasingly, when faced with a system that is unable to read the biometric information of the <span class="italic">individual</span>, it is the individual who is considered suspect. At the same time if the correlation algorithms incorrectly identify an individual &mdash; as was the case with the Boston Bomber recognition that exploited crowd sourced identification matched with algorithmic prediction to mount a witch hunt for an innocent person &mdash; the error is still thought of as human and the human needs to be remedied.<br>
<br>

 

This new order of verification, where we no longer tell truth, but our truth will have to measure to a level that the digital systems verify, is another condition whereby informational truth values are collapsing and we essentially have multiple modalities and registers of information which, upon verification, also inherit veracity.<br>
<br>

 
<span class="bold">From authorisation to authentication</span><br>
<br>

 

Within the older structures of information, truth was supported by other sources that could further be supported by an ever-expanding terrain of sources that were authorised as truthful. Information, when it made a claim, needed to be supported by other informational sources of good standing. This condition of authorisation was based on the first doctrines of logic. It suggested that if a source gives out good information once, then the chances are that it will give good information the next time. And the more times it fulfils this expectation, the more robust it becomes till it is accepted as always truth-telling. Indeed, the question of authorisation was perhaps at the centre of representational politics. The gatekeepers of information were thus clearly defined and there was a stable sense of what counts as an authorised source. We developed conditions of anonymity, ethical authorisation, fact checking, investigation and research that enabled for information industries to grow. However, in this logical universe, the sources are static. They are non-variable and continue to stand with gravitas in an established context.<br>
<br>

 

Within the digital networks, this idea of static nodes that faithfully perform their attributed function has been lost. Within a digital network, a node is not a pre-conceived, long-standing entity. It is a variable, ad-hoc point within a system that is activated based on the needs and functions of traffic transfer. Once the activity has been achieved, the node goes back to lurking, existing as a potential node, but not quite a node. When a node collapses &mdash; like a server blackout on the Internet for example &mdash; another node that has the same capacity is put into service and the replacement is, for the user, indistinguishable. In this state of multiple and variable nodes, each with no other function than that for which they are activated, by discerning protocols and vectoral algorithms that process a transfer of traffic in the network, the principles and capacity of authorisation makes no sense. These nodes only enact authentication, which is a system of fact-checking based on the central processing units that are engineered and authenticated to perform one particular task that is limited in scope.<br>
<br>

 

Authenticated nodes operating together to form a system are the idea behind autonomous driving vehicles, and illustrate precisely why we have such an uproar around their introduction. Autonomous driving vehicles are authenticated on the protocols of driving and keeping the riders safe. However, if they were ever faced with <span class="italic">ethical</span> dimensions that they do not recognise, then the <span class="italic">decision</span> that they make cannot be judged as a right or a wrong, or not even thought of as a problem. This ethical dilemma of the <span class="italic">Trolley Problem</span> is a human problem along with its affiliated human concerns and anxieties. It is not the problem of the digital network engaged in self-learning for its own simulated verified authentication structures.<br>
<br>

 

These brief comparisons, hopefully make a case for why we need to stop thinking of fake news as a content and information problem, and instead start examining the new conditions of meaning-making, human agency, and machine logic that the accelerated digitization of our contemporary times has brought. If we do accept that fake news is not a new but a historically marked category, and that the current emergence of fake news is not about the news but about the collapse of our representational, modernist measures of truth-telling, then we can also attain the next step whereby we no longer denounce fake news as undesirable, in recognizing that the truth-telling capacities of erstwhile information production nodes is as compromised as of the professional misinformation architects who service both the side of the debates.<br>
<br>

 

Distancing <span class="italic">fake news</span> from the fear-mongering of provincial moralism might even offer us a way to recognise fake news as symptomatic of subversive and radical activity that is being censored, contained, penalised and punished under the accusations of fakeness. Let me illustrate this with a story that has all the characteristics of Internet humour and subversion, as a hard political stance that was taken by young digital natives in China who were countering the state sponsored <span class="italic">fake news</span> with some of their own challenged the information safeguards that often exclude and penalise dissonant voices.<br>
<br>

 
<span class="bold">My false versus your false &hellip;</span><br>
<br>

 

While leaks of classified information have warned us against taking the state and corporate voices as sacred, in China, the explicit governmental restrictions on things that can and cannot be said makes the Internet a veritable battleground of information politics. China’s policy of making information that is <span class="italic">seditious</span> and disrespectful invisible often leads to filtering and censoring of information from the social and user-generated web. Search engines like Google and DIY knowledge spaces like Wikipedia have already faced fierce control and regulation. In fact, one of the ways of diminishing the power of these companies is to create direct rivals that cater to the local population and consequently embedding the users in more easily controlled environments.<br>
<br>

 

A locally-grown digital encyclopedia, Baidu Baike, was made popular in 2005 and was offered by the Chinese Internet search company Baidu. With more than 1.5 million Chinese language articles, Baidu has become a space for much debate and discussion with the younger users in China. Offered as a competitor to Wikipedia, Baidu implements heavy self-censorship to avoid displeasing the Chinese Government and remains dedicated to removing offensive material with a special emphasis on pornographic and political events.<br>
<br>

 

It is in this restrictive, self-regulated regime of information sharing and knowledge production, where all news is already tainted with a fakeness that serves the ideologies of those in power, that the young users of the social web decided to stage an online protest. Just like Wikipedia, Baidu is editable by users who sign in and add information on a variety of topics. When Baidu decided to clamp down on free speech by removing material that would have offended the censorship mechanism of China the users coordinated to perform an act that would have been thought of as vandalism. They willingly introduced false information that could be justified by the terms of service of Baidu but would defy the attempts at blocking free expression. Targeting the obscenity clauses, a bunch of anonymous users created a page of the »10 legendary obscene beasts of China«<span class="footnoteintext"><sup>2</sup></span> that exploited the localised capacity of Mandarin to play with double meanings using the different homophones and character tones that are a part of everyday Chinese conversations. These 10 beasts were all fictitious and their descriptions seemed innocent and almost drew from fantasy. However, when spoken aloud, and with a slight difference in intonation, these names would become swear words and symbols of political critique that would be recognised by any Mandarin speaking person.<br>
<br>

 

The most famous of these creations was Cao Ni Ma (Chinese: <span class="chinese">草泥马</span>), literally »Grass Mud Horse«, which uses the same consonants and vowels with different tones for the Chinese language profanity which translates into »Fuck Your Mother« cào nǐ mā (肏你妈). This mythical animal belonging to the Alpaca race had dire enemies called héxiè (<span class="chinese">河蟹</span>), literally translated as »river crabs«, very close to the word héxié (<span class="chinese">和谐</span>) meaning harmony, referring to the government’s declared ambition of creating a »harmonious society« through censorship. The Cao Ni Ma is an example of how the clampdown on digital voices was challenged with joy, humour, and defiance. The Cao Ni Ma has now become a popular icon appearing in videos distributed on YouTube, in fake documentaries, in popular Chinese internet productions, and even in themed toys and plushies which all serve as mobilising points against the censorship and control that the Chinese government is trying to maintain.<br>
<br>

 

Those who do not understand the context and the political weapon that the digital users were wielding often dismiss this as fake news, false information, or acts of vandalism. Even within the Chinese speaking spheres, there was a large conversation on how this fake information is dangerous and should be removed. However, the protesters made their point strong and clear, because not only did the page survive the censorship mechanisms of Baidu, but it even made it through the monitoring agencies of the state which failed to recognise the profane and the dissident intent of these productions.<span class="footnoteintext"><sup>3</sup></span> The legendary obscene beasts have now become inspiring and iconic symbols of the slow and steady protest against censorship and for the right to free speech that Chinese web is experiencing. They also remind us that just because news and information comes from a seemingly authoritative source does not mean that the news is not manipulated, changed, and arranged to send a specific message across. Sometimes, the only way to fight this indoctritainment (indoctrination as entertainment) is to mark it as false and counter it with other kinds of fakeness. The battle of my fake versus your fake is what we are witnessing right now, and how we resolve it, by producing safeguards that protect the interest of the public, and structures that hold all news producers and technology infrastructure providers accountable is going to determine the informational future that we will inherit.<br>
<br>

 
<span class="bold">TL;DR</span><br>
<br>

 

I have taken you through this entire journey to re-examine our understanding of the contemporary fake news phenomenon and our response to it. I began by proposing that the fakeness of information or the truthIness of news is not an objective or a benign criterion. It is bolstered by various social, political, cultural, and economic agendas which often manipulate the perception and distribution of these characterizations to suit their own purpose. I also suggested that the question of sorting and sifting good information from bad information is not a new thing, but has been around since the beginning of written cultures &mdash; that indeed, our idea of what counts as robust information is triangulated through the questions of who gets to be an author, what information can be authorised, and the authority that stamps information as legitimate. Taking a temporal leap from the pre-print scribal cultures to the current digital turn, I have argued that our preoccupation with information and its soundness does not have to be entered into an accounting structure of good and bad. Instead, we need to see the resurfacing of this old concern as a transition that we are going through, as we see our lives rendered legible, intelligible, and accessible through digital technologies that value simulation over representation, authentication over authorisation, and verification over veracity.<br>
<br>

 

Once we realise that there is nothing inherent in information that we deem as good or true or correct, we realise that information production, circulation, and negotiation is a battlefield. Through the story of the legendary obscene beasts in China, I have proposed that information wars are real and are being waged as the digital democratisation enables multiple and diverse conflicting voices to be seen and heard. The age of centralised information authorisation is over, and as we deal with multiple information streams that mark our overloaded subjectivities, we will have to realise that what makes information real or not is about intention and affect. To think of information as objective and neutral is a fallacy. Instead we need to emphasise that what we need to make transparent are the multiple intentions, emotions, affects, and effects that contextualise this information. It is time to start thinking of information as human. This idea of information as human necessitates bringing in the elements of how individuals are involved, implicated, affected, and intended in our networks of fake news and truthful information. <br>
  
  <br>
<hr color="#3e0694" size="1px">
  <br>
  

<span class="footnotebold">FOOTNOTES</span><span class="footnotes"> <br> <br>
</span>

<span class="footnotebold">1</span> <span class="footnotes">&nbsp;&nbsp;Chun, in her critical work on Software Studies argues that the digital often presents itself as an explanatory tool. Especially with visualization, the digital interfaces propose that they are representations that bear fidelity with the external world. However, the digital network has fidelity only unto itself, and the visualisations that we see are often opaque, diverting all attention only to the logics of internal mechanics, and thus must be not read as having direct correlations with the larger systems of life and living that they occupy. </span><br> 
<br>

<span class="footnotebold">2 </span><span class="footnotes">&nbsp;&nbsp;More can be found about this list at http://www.danwei.org/humor/baidu_baike_fake_entries.php </span><br> <br>

<span class="footnotebold">3</span><span class="footnotes"> &nbsp;&nbsp;It is particularly important to point out that this shift is symptomatic of how the older safeguards of truth-telling in traditional media have changed. The different mechanisms that were developed for ethical media work like claiming authorised sources, fact-checking, etc. produced an information ecosystem where human discretion prevailed, thus offering very clear political biases and truth-claims in the information production systems. However, with the Baidu example, what I want to emphasise is that the older ideas of one set of information being true and other no, are collapsing. With the digital, the shift is not in one versus the other. We now have a state where both competing sets of information are being equally subjected to manipulation and hence suspicion. The conditions of this multiple truth-telling are enabled by algorithms, bots, data crawling sets, visualisation software, and vectors and protocols of news aggregation and circulation. This leads to a shift form information that could be verified because it was authorised &mdash; somebody could be within the system but still be counted as non-authorial &mdash; to a space where information is accepted upon authentication. In this mode, as long as you are made legible into the system, your information will be treated as equal to all other competing information streams and there will be no more discrimination, human or otherwise, between fake and authentic sources. </span><br> <br><br>


<span class="footnotes"><span class="footnotebold">REFERENCES</span><br>
<br>

Chun, W. H. K. (2008). </span><span class="footnoteitalic">Control and Freedom: Power and Paranoia in the Age of Fiber Optics</span><span class="footnotes">. Cambridge, Mass.: The MIT Press.<br>
<br>

Foucault, M. (1975). </span><span class="footnoteitalic">Discipline and Punish: The Birth of the Prison</span><span class="footnotes">. (A. Sheridan, Trans.) (1st American ed edition). New York: Pantheon Books.<br><br>

Liang, L. (2011). A brief history of the Internet from the 15th to 18th Century. In G. Lovink &amp; N. Tkacz (Eds.), </span><span class="footnoteitalic">Critical point of view. A wikipedia reader</span><span class="footnotes">. Amsterdam: Institute of Network Cultures.<br><br>

Losh, E. (2014). </span><span class="footnoteitalic">The War on Learning: Gaining Ground in the Digital University</span><span class="footnotes">. Cambridge, Mass: The MIT Press.<br><br>

Rajadhyaksha, A. (Ed.). (2013).</span><span class="footnoteitalic"> In the Wake of Aadhaar: Digital Ecosystem of Governance in India</span><span class="footnotes">. Bangalore: Centre for the Study of Culture &amp; Society.<br><br>

Rancière, J. (1991). </span><span class="footnoteitalic">The Ignorant Schoolmaster: Five Lessons in Intellectual Emancipation</span><span class="footnotes"> (1. edition). Stanford, Calif: Stanford University Press.<br><br>

Rose, M. (1993). </span><span class="footnoteitalic">Authors and Owners: The Invention of Copyright</span><span class="footnotes">. Cambridge, Mass: Harvard University Press.<br><br>

Shannon, C. &amp; Weaver, W. (1948).</span><span class="footnoteitalic"> A Mathematical Model of Communication</span><span class="footnotes">. Urbana, IL: University of Illionois Press.<br><br>

Kracauer, S. (1995). »The Group as a bearer of ideas«, </span><span class="footnoteitalic">The Mass Ornament: Weimar essays</span><span class="footnotes">. Tr. Thomas Y. Levin. Cambridge: Harvard University Press.<br><br><br>

</span><span class="footnotebold">THE AUTHOR</span><span class="footnotes"><br>
<br>

Nishant Shah is a professor of culture and aesthetics of digital media at Leuphana University, Germany, and the Dean of Graduate School at ArtEZ University of the Arts, The Netherlands. His work is at the intersections of digital technology, computing cultures, identity politics, and education.</span>
</body>
</html>